{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJe1AqlgKzlR",
        "outputId": "515d43bd-4130-4e03-8919-c1b7b4441d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-y117vvh7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-y117vvh7\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5cd225851b7638f3f6d55a19328295f16c014079\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.0.3-py3-none-any.whl size=7432 sha256=ad99cf1e6175f37f13398802e9e82d42885745e385f9d1c2ce678f3d359f3a95\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oe7s7jpl/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3NbyeRELFbu",
        "outputId": "eda108ed-8aee-4bfd-a73f-3a0a8b61e112"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Source files will be saved in \"/tmp/tmp04xvqnh4\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfcPyPl4LM6h",
        "outputId": "d5b9fc7d-8f85-4cf3-b87e-db2ed978c0c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb  9 17:52:48 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "-vG9PbHfzwYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Program"
      ],
      "metadata": {
        "id": "CJXNLt49z5LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "#define WIDTH 16\n",
        "\n",
        "\n",
        "// Matrix multiplication on the (CPU) host\n",
        "void MatrixMulOnHost(int* M, int* N, int* P, int Width)\n",
        "{\n",
        "  for (int i = 0; i < Width; ++i)\n",
        "  {\n",
        "    for (int j = 0; j < Width; ++j)\n",
        "    {\n",
        "      double sum = 0;\n",
        "      for (int k = 0; k < Width; ++k)\n",
        "      {\n",
        "      double a = M[i * Width + k];\n",
        "      double b = N[k * Width + j];\n",
        "      sum += a * b;\n",
        "      }\n",
        "      P[i * Width + j] = sum;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "float time_diff(struct timeval *start, struct timeval *end) {\n",
        "  return (end->tv_sec - start->tv_sec) + 1e-6 * (end->tv_usec - start->tv_usec);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    struct timeval start, end;\n",
        "\n",
        "\n",
        "    int* M, *N, *P;\n",
        "    int* a;\n",
        "    int size = WIDTH * WIDTH * sizeof(int);\n",
        "\n",
        "\n",
        "    M = (int*)malloc(size);\n",
        "    N = (int*)malloc(size);\n",
        "    P = (int*)malloc(size);\n",
        "\n",
        "\n",
        "    for (int i = 0; i < WIDTH * WIDTH; ++i) {\n",
        "        M[i] = rand() % 10;\n",
        "        N[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "\n",
        "    MatrixMulOnHost(M, N, P, WIDTH);\n",
        "\n",
        "    gettimeofday(&end, NULL);\n",
        "\n",
        "\n",
        "    /* printf(\"Result Matrix:\");\n",
        "    for (int j =0 ; j<WIDTH*WIDTH ; j=j+1){\n",
        "        if (j%WIDTH == 0){printf(\"\\n %d \\t\",*(P+j));}\n",
        "        else{printf(\"%d\\t\",*(P+j));}\n",
        "    }\n",
        "    */\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    printf(\"time spent: %0.8f sec\\n\", time_diff(&start, &end));\n",
        "\n",
        "    free(M);\n",
        "    free(N);\n",
        "    free(P);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "DIkrSuPJLQgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9419670-5f8a-4ee7-8d8c-9b7480cc4470"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "time spent: 0.00001600 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel - I"
      ],
      "metadata": {
        "id": "Kk6Xo4AK3zAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define WIDTH 16\n",
        "#define TILE_WIDTH 2\n",
        "#define N_THREADS 256\n",
        "\n",
        "// Matrix multiplication kernel â€“ per thread code\n",
        "__global__ void MatrixMulKernel(int* d_M, int* d_N, int* d_P, int Width)\n",
        "{\n",
        "  // Calculate the row index of the d_P element and M\n",
        "  int Row = blockIdx.y*TILE_WIDTH + threadIdx.y;\n",
        "  // Calculate the column index of d_P and N\n",
        "  int Col = blockIdx.x*TILE_WIDTH + threadIdx.x;\n",
        "  float Pvalue = 0;\n",
        "  // each thread computes one element of the block sub-matrix\n",
        "  for (int k = 0; k < Width; ++k) Pvalue += d_M[Row*Width+k] * d_N[k*Width+Col];\n",
        "  d_P[Row*Width+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "float time_diff(struct timeval *start, struct timeval *end) {\n",
        "  return (end->tv_sec - start->tv_sec) + 1e-6 * (end->tv_usec - start->tv_usec);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    struct timeval start;\n",
        "    struct timeval end;\n",
        "\n",
        "    int* M, *N, *P;\n",
        "\n",
        "    int size = WIDTH * WIDTH * sizeof(int);\n",
        "\n",
        "    M = (int*)malloc(size);\n",
        "    N = (int*)malloc(size);\n",
        "    P = (int*)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < WIDTH * WIDTH; ++i) {\n",
        "        M[i] = rand() % 10;\n",
        "        N[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    int *d_M, *d_N, *d_P;\n",
        "    cudaMalloc((void**)&d_M, size);\n",
        "    cudaMalloc((void**)&d_N, size);\n",
        "    cudaMalloc((void**)&d_P, size);\n",
        "\n",
        "    cudaMemcpy(d_M, M, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_N, N, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "    MatrixMulKernel<<<(WIDTH * WIDTH + N_THREADS - 1) / N_THREADS, N_THREADS>>>(d_M, d_N, d_P, WIDTH);\n",
        "    cudaDeviceSynchronize();\n",
        "    gettimeofday(&end, NULL);\n",
        "\n",
        "    cudaMemcpy(P, d_P, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    /*printf(\"Result Matrix:\");\n",
        "    for (int j =0 ; j<WIDTH*WIDTH ; j=j+1){\n",
        "        if (j%WIDTH == 0){printf(\"\\n %d \\t\",*(P+j));}\n",
        "        else{printf(\"%d\\t\",*(P+j));}\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    */\n",
        "    printf(\"time spent: %0.8f sec\\n\", time_diff(&start, &end));\n",
        "\n",
        "    free(M);\n",
        "    free(N);\n",
        "    free(P);\n",
        "    cudaFree(d_M);\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGXMpX-C4WfR",
        "outputId": "decba96a-fed2-4594-8140-a5c9ad361d53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time spent: 0.11361100 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel - II"
      ],
      "metadata": {
        "id": "U5LuFJxP4rCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "#define WIDTH 16\n",
        "#define TILE_WIDTH 2\n",
        "#define N_THREADS 256\n",
        "\n",
        "__global__ void matrixMulTiled(const int* M, const int* N, int* P, int width) {\n",
        "    __shared__ int Mds[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int Nds[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    int bx = blockIdx.x, by = blockIdx.y;\n",
        "    int tx = threadIdx.x, ty = threadIdx.y;\n",
        "\n",
        "    int row = by * TILE_WIDTH + ty;\n",
        "    int col = bx * TILE_WIDTH + tx;\n",
        "\n",
        "    int Pvalue = 0;\n",
        "\n",
        "    for (int ph = 0; ph < width / TILE_WIDTH; ++ph) {\n",
        "        Mds[ty][tx] = M[row * width + ph * TILE_WIDTH + tx];\n",
        "        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; ++k) {\n",
        "            Pvalue += Mds[ty][k] * Nds[k][tx];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    P[row * width + col] = Pvalue;\n",
        "}\n",
        "\n",
        "float time_diff(struct timeval *start, struct timeval *end) {\n",
        "  return (end->tv_sec - start->tv_sec) + 1e-6 * (end->tv_usec - start->tv_usec);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int* M, *N, *P;\n",
        "    int size = WIDTH * WIDTH * sizeof(int);\n",
        "\n",
        "    M = (int*)malloc(size);\n",
        "    N = (int*)malloc(size);\n",
        "    P = (int*)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < WIDTH * WIDTH; ++i) {\n",
        "        M[i] = rand() % 10;\n",
        "        N[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    int *d_M, *d_N, *d_P;\n",
        "    cudaMalloc((void**)&d_M, size);\n",
        "    cudaMalloc((void**)&d_N, size);\n",
        "    cudaMalloc((void**)&d_P, size);\n",
        "\n",
        "    cudaMemcpy(d_M, M, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_N, N, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimGrid(WIDTH / TILE_WIDTH, WIDTH / TILE_WIDTH);\n",
        "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "\n",
        "    struct timeval start, end;\n",
        "    gettimeofday(&start, NULL);\n",
        "    matrixMulTiled<<<dimGrid, dimBlock>>>(d_M, d_N, d_P, WIDTH);\n",
        "    cudaDeviceSynchronize();\n",
        "    gettimeofday(&end, NULL);\n",
        "\n",
        "    cudaMemcpy(P, d_P, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    /*printf(\"Result Matrix:\\n\");\n",
        "    for (int j = 0; j < WIDTH * WIDTH; ++j) {\n",
        "        if (j % WIDTH == 0) {\n",
        "            printf(\"\\n %d \\t\", P[j]);\n",
        "        } else {\n",
        "            printf(\"%d\\t\", P[j]);\n",
        "        }\n",
        "    }\n",
        "    */\n",
        "    printf(\"\\n\");\n",
        "    printf(\"time spent: %0.8f sec\\n\", time_diff(&start, &end));\n",
        "\n",
        "\n",
        "    free(M);\n",
        "    free(N);\n",
        "    free(P);\n",
        "    cudaFree(d_M);\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVMGoI9w4ire",
        "outputId": "bff69cee-9420-4520-ace3-a6cae9c1002f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "time spent: 0.04674900 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "J01mvWo58eSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel - I\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ICG6o9WE5MXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "const int N = 4194304;\n",
        "const int threadsPerBlock = 256;\n",
        "const int arraySize = N;\n",
        "const int blocksPerGrid = (arraySize + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "__global__ void reduce0(int *g_idata, int *g_odata) {\n",
        "  extern __shared__ int sdata[];\n",
        "  // each thread loads one element from global to shared mem\n",
        "  unsigned int tid = threadIdx.x;\n",
        "  unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  sdata[tid] = g_idata[i];\n",
        "  __syncthreads();\n",
        "  // do reduction in shared mem\n",
        "  for(unsigned int s=1; s < blockDim.x; s *= 2)\n",
        "  {\n",
        "    if (tid % (2*s) == 0)\n",
        "    {\n",
        "    sdata[tid] += sdata[tid + s];\n",
        "    }\n",
        "  __syncthreads();\n",
        "  }\n",
        "  // write result for this block to global mem\n",
        "  if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "float time_diff(struct timeval *start, struct timeval *end) {\n",
        "  return (end->tv_sec - start->tv_sec) + 1e-6 * (end->tv_usec - start->tv_usec);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    struct timeval start, end;\n",
        "\n",
        "    int* h_input = (int*)malloc(arraySize * sizeof(int));\n",
        "    int* h_output = (int*)malloc(blocksPerGrid * sizeof(int));\n",
        "\n",
        "\n",
        "    for (int i = 0; i < arraySize; ++i) {\n",
        "        h_input[i] = i;\n",
        "    }\n",
        "\n",
        "    int* d_input, *d_output;\n",
        "    cudaMalloc((void**)&d_input, arraySize * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, blocksPerGrid * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "\n",
        "    reduce0<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    gettimeofday(&end, NULL);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, blocksPerGrid * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    int result = 0;\n",
        "    for (int i = 0; i < blocksPerGrid; ++i) {\n",
        "        result += h_output[i];\n",
        "    }\n",
        "\n",
        "    printf(\"time spent: %0.8f sec\\n\", time_diff(&start, &end));\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCXtPiXE4th8",
        "outputId": "7dc7d864-3ed3-4f4c-d2af-c6af05f0f627"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time spent: 1.74649894 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel - II"
      ],
      "metadata": {
        "id": "Fp6vrBbW5hPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "const int N = 67108864;\n",
        "const int threadsPerBlock = 256;\n",
        "const int arraySize = N;\n",
        "const int blocksPerGrid = (arraySize + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "__global__ void reduce0(int *g_idata, int *g_odata) {\n",
        "  extern __shared__ int sdata[];\n",
        "  // each thread loads one element from global to shared mem\n",
        "  unsigned int tid = threadIdx.x;\n",
        "  unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  sdata[tid] = g_idata[i];\n",
        "  __syncthreads();\n",
        "  for (unsigned int s=1; s < blockDim.x; s *= 2)\n",
        "  {\n",
        "    int index = 2 * s * tid;\n",
        "    if (index < blockDim.x) {\n",
        "    sdata[index] += sdata[index + s];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  // write result for this block to global mem\n",
        "  if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "float time_diff(struct timeval *start, struct timeval *end) {\n",
        "  return (end->tv_sec - start->tv_sec) + 1e-6 * (end->tv_usec - start->tv_usec);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    struct timeval start, end;\n",
        "\n",
        "    int* h_input = (int*)malloc(arraySize * sizeof(int));\n",
        "    int* h_output = (int*)malloc(blocksPerGrid * sizeof(int));\n",
        "\n",
        "\n",
        "    for (int i = 0; i < arraySize; ++i) {\n",
        "        h_input[i] = i;\n",
        "    }\n",
        "\n",
        "    int* d_input, *d_output;\n",
        "    cudaMalloc((void**)&d_input, arraySize * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, blocksPerGrid * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "\n",
        "    reduce0<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    gettimeofday(&end, NULL);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, blocksPerGrid * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    int result = 0;\n",
        "    for (int i = 0; i < blocksPerGrid; ++i) {\n",
        "        result += h_output[i];\n",
        "    }\n",
        "\n",
        "    printf(\"time spent: %0.8f sec\\n\", time_diff(&start, &end));\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yfnT4X55dB-",
        "outputId": "4dbf02a0-a1b7-4840-efde-4a35091fafa0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time spent: 1.75620699 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel - III"
      ],
      "metadata": {
        "id": "dAsT0S405zz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "const int N = 67108864;\n",
        "const int threadsPerBlock = 256;\n",
        "const int arraySize = N;\n",
        "const int blocksPerGrid = (arraySize + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "__global__ void reduce0(int *g_idata, int *g_odata) {\n",
        "  extern __shared__ int sdata[];\n",
        "  unsigned int tid = threadIdx.x;\n",
        "  unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;\n",
        "  sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];\n",
        "  __syncthreads();\n",
        "  for (unsigned int s=blockDim.x/2; s>0; s>>=1)\n",
        "  {\n",
        "    if (tid < s) {\n",
        "    sdata[tid] += sdata[tid + s];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  // write result for this block to global mem\n",
        "  if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "float time_diff(struct timeval *start, struct timeval *end) {\n",
        "  return (end->tv_sec - start->tv_sec) + 1e-6 * (end->tv_usec - start->tv_usec);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    struct timeval start, end;\n",
        "\n",
        "    int* h_input = (int*)malloc(arraySize * sizeof(int));\n",
        "    int* h_output = (int*)malloc(blocksPerGrid * sizeof(int));\n",
        "\n",
        "\n",
        "    for (int i = 0; i < arraySize; ++i) {\n",
        "        h_input[i] = i;\n",
        "    }\n",
        "\n",
        "    int* d_input, *d_output;\n",
        "    cudaMalloc((void**)&d_input, arraySize * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, blocksPerGrid * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "\n",
        "    reduce0<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    gettimeofday(&end, NULL);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, blocksPerGrid * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    int result = 0;\n",
        "    for (int i = 0; i < blocksPerGrid; ++i) {\n",
        "        result += h_output[i];\n",
        "    }\n",
        "\n",
        "    printf(\"time spent: %0.8f sec\\n\", time_diff(&start, &end));\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8u0ondb5jAw",
        "outputId": "21629c35-4db4-4998-e37c-280bc81a7920"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time spent: 1.70336902 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ACz0J6ki5uRe"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}